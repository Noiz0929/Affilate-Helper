name: Run Proxy Scraper & Aff Clicker

on:
  schedule:
    - cron: '*/5 * * * *' # Every 40 minutes
  workflow_dispatch: # Manual trigger

jobs:
  run-scripts:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Install Chrome v135 (for testing)
        run: |
          wget https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/135.0.7049.114/linux64/chrome-linux64.zip
          unzip chrome-linux64.zip
          sudo mv chrome-linux64 /opt/chrome
          sudo ln -sf /opt/chrome/chrome /usr/bin/google-chrome

      - name: Install ChromeDriver v135
        run: |
          wget https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/135.0.7049.114/linux64/chromedriver-linux64.zip
          unzip chromedriver-linux64.zip
          sudo mv chromedriver-linux64/chromedriver /usr/local/bin/chromedriver
          sudo chmod +x /usr/local/bin/chromedriver

      - name: Confirm versions
        run: |
          google-chrome --version
          chromedriver --version

      - name: Run GitScraping.py
        run: python proxy_tools/GitScraping.py

      - name: Run AffClicker_w_Aiohttp.py
        run: python AffClicker_w_Aiohttp.py
